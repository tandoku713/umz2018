{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresja Logistyczna: wieloklasowość"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tematem dzisiejszych zajęć jest regresja logistyczna dla wielu (więcej niż 2) klas. Posłużymy się zbiorem danych [MNIST](http://yann.lecun.com/exdb/mnist/), który zawiera 50 tyś. obrazków cyfr. Naszym zadaniem będzie wytrenować model, na podstawie obrazka rozpozna jak to jest cyfra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadania na dzisiejsze zajęcia są podzielone na 3 części: wczytanie i przygotowanie danych, implementacja regresji logistycznej i użycie modelu z pakietu `sklearn`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytanie i przygotowanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 1** Pobierz cztery pliki `*-images-idx3-ubyte.gz` ze strony http://yann.lecun.com/exdb/mnist/ i rozpakuj (!) w tym samym katalogu, w którym znajduje się notatnik (pod Linuxem możesz wykorzystać skrypt `download.sh`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By uprościć zadanie, zostały przygotowane dwie funkcje:\n",
    " * `readMnist`: funkcja wczytująca zestaw danych.\n",
    " * `showImage`: fukcja wyświetlająca pojedyńczy obrazek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def readMnist(dataset = \"training\", path = \".\"):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "\n",
    "    get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "    return [get_img(i) for i in range(len(lbl))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(image):\n",
    "    \"\"\"\n",
    "    Render a given numpy.uint8 2D array of pixel data.\n",
    "    \"\"\"\n",
    "    from matplotlib import pyplot\n",
    "    import matplotlib as mpl\n",
    "    fig = pyplot.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = readMnist()\n",
    "valid_data = readMnist(\"testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Każdy przykład testowy składa się z dwóch elementów: cyfry oraz obrazu, który odpowiada tej cyfrze:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 2** Korzystając z fukcji `showImage` wyświetl pierwsze 5 przykładów z zbiory trenującego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Każdy obrazek ma rozmiar 28 na 28 pikseli. Kazdy piksel będzie cechą dla naszego modelu regresji logistycznej (będziemy mieć 28 * 28 = 784 cech). Każdy piksel to liczba pomiedzy 0 a 256 (skala szarości). Ponadto będziemy meić 10 klas. Każda klasa będzie reprezentować cyfrę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 3** Napisz funkcję, która przeskaluje dane wejściowe do przedziału od 0 do 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 4** Napisz fukcję, która rozdzieli `train_data` i `valid_data` na zbiory wejściowe i wyjściowe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = \n",
    "train_y = \n",
    "\n",
    "valid_X = \n",
    "valid_y = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeden kontra pozostałe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na poprzednich zajęciach poznaliśmy regresję logistyczną, która działa na 2 klasach. Najprostszym podejściem jest klasyfikacja typu *One-vs-All*. Polega ona na zbudowaniu modelu modelu regresji logistycznej dla każdej klasy osobno. W naszym przypadku będzie to napisania modeli, które rozpoznają cyfry po kolei:0, 1, ..., 9.\n",
    "\n",
    "Podczas testowania uruchmiamy wszystkie modele i sprawdzamy, który z nich ma najwyższe prawdopodobieństwo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 5 (złożone)**\n",
    "\n",
    "Zaimplementuj model *One-vs-All*:\n",
    " * Przygotuj 10 zestawów trenujących oraz testowych. Dla cyfry $i$, $i$-ty zestaw danych powienien mieć dwie klasy \\[1, 0\\].\n",
    " * Wytrenuj 10 modeli na wytrenowanych danych.\n",
    " * Przetestuj wszystkie modele osobno.\n",
    " * Przetestuj wszytkie modele jednocześnie. Dla każdego przypadku testowego, uruchom wszystkie 10 modeli. Przypisz indeks modelu z najwyższym prawdopodobieństem jako wyjście całego systemu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementacja regresji logistycznej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tej cześci ćwiczeń skupimy się na ręcznej implementacji klasyfikatora regresji logistycznej. Na chwilę wrócimy do modelu z dwoma klasami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator01(dataset = \"training\", path = \".\", batch_size=32):\n",
    "    ii = 0\n",
    "    labels = []\n",
    "    images = []\n",
    "    for label, image in readMnist(dataset, path):\n",
    "        if label in (0, 1):\n",
    "            labels.append(label)\n",
    "            images.append(image.reshape((28 * 28,)))\n",
    "            ii += 1\n",
    "            if ii == batch_size:\n",
    "                yield np.array(images, dtype='float32') / 256.0, np.array(labels, dtype=\"int64\")\n",
    "                ii = 0\n",
    "                labels = []\n",
    "                images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 6** Zaimplementuj następujące funkcję:\n",
    " * `forward(x, weights, bias)`: oblicza $\\sigma(dot(weights, x) + bias)$\n",
    " * `loss(labels, out)`: oblicza entropię krzyżową.\n",
    " * `grad_weights`: oblicza gradient wszystkich zmiennych z `weights` względem funkcji kosztu. Ponadto oblicza średnią po kolumnach.\n",
    "\n",
    "Objaśnienia:\n",
    " * `dot`: iloczyn skalarny\n",
    " * `weights` jest listą długości 784 zawierającą wagi modelu\n",
    " * `x` jest wymiaru 32 na 784 (lista list)\n",
    " * `labels` jest listą etykiet (0 lub 1) rozmiaru 32\n",
    " * `y`: jest wyjściem z funkcji `forward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigma(x):\n",
    "    return [1.0 / (1 + np.exp(-x_i)) for x_i in x]\n",
    "\n",
    "def forward(x, weights, bias):\n",
    "    pass\n",
    "\n",
    "def grad_weights(out, x, y):\n",
    "    grad_x = [0.0 for i in range(len(x[1]))]\n",
    "    \n",
    "    for x_row, y_i, out_i in zip(x, y, out):\n",
    "        tmp = []\n",
    "        for x_i in x_row:\n",
    "            tmp.append((out_i - y_i) * x_i)\n",
    "        for i in range(len(grad_x)):\n",
    "            grad_x[i] += tmp[i]\n",
    "            \n",
    "    for i in range(len(grad_x)):\n",
    "        grad_x[i] /= len(y)\n",
    "    \n",
    "    return grad_x  \n",
    "\n",
    "def grad_bias(out, y):\n",
    "    return sum([out_i - y_i for out_i, y_i in zip(out, y)]) / len(out)\n",
    "\n",
    "def loss(y, out):\n",
    "    pass\n",
    "\n",
    "def update_weights(weights, bias, grads, lr):\n",
    "    pass\n",
    "\n",
    "    \n",
    "def train_logistic_regression(epochs, batch_generator, lr=0.01):\n",
    "    weights = np.random.normal(0, 0.05, 28 * 28)\n",
    "    bias = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in batch_generator():\n",
    "            x = batch[0]\n",
    "            y = batch[1]\n",
    "            \n",
    "            out = forward(x, weights, bias)\n",
    "\n",
    "            epoch_loss = sum(loss(y, out)) / len(y)\n",
    "            print(\"loss\", epoch_loss)\n",
    "            grads = (grad_weights(out, x, y), grad_bias(out, y))\n",
    "            \n",
    "            weights, bias = update_weights(weights, bias, grads, lr)\n",
    "    return weights, bias    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zrobiwszy możemy uruchomić model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias = train_logistic_regression(1, batch_generator01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzamy, na których przykładach, nasz model pomylił się:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for e in batch_generator01('testing', '.', 1):\n",
    "    img = e[0]\n",
    "    label = e[1][0]\n",
    "    if int(forward(img, weights, bias)[0] >= 0.5) != label:\n",
    "        showImage(img.reshape((28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wieloklasowa regresja logistyczna (albo regresja softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 7** Zaimplementuj funckję [``softmax``](https://en.wikipedia.org/wiki/Softmax_function):\n",
    "\n",
    "$$ softmax(x_i) = \\frac{e^{x_i}}{\\sum{e^{x_j}}} $$\n",
    "\n",
    "\n",
    "Przykład:\n",
    "\n",
    "wejście:\n",
    "\n",
    "``\n",
    "[[0.2, 0.3, 0.1],\n",
    " [1.0, 2.0, -3]]``\n",
    "\n",
    "poprawna odpowiedź:\n",
    "\n",
    "``\n",
    "[[0.3322249935333472, 0.36716540111092544, 0.3006096053557273],\n",
    " [0.2676231541498623, 0.7274751568004647, 0.004901689049672921]]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(matrix):\n",
    "    for row in matrix:\n",
    "        row_sum = 0.0\n",
    "        for col in row:\n",
    "            row_sum += np.exp(col)\n",
    "        \n",
    "        for i in range(len(row)):\n",
    "            row[i] = np.exp(row[i]) / row_sum\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importujemy ten sam model jak w przypadku regresji 2-klasowej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Musimy ustawić opcję `multi_class` na `multinomial` i `solver` na `saga`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', penalty='l1', solver='saga', tol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trening modelu nie różni się od treningu modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([x[1].flatten() for x in readMnist()], [x[0] for x in readMnist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predykcja również zostaje niezmieniona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict([x[1].flatten() for x in readMnist('testing')])\n",
    "y_test = [x[0] for x in readMnist('testing')]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(predicted, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeżeli dotarłeś do tego miejsca podczas zajeć: Gratuluję! Możesz albo skończyć zajęcia, ale zachęcam Cię do jeszcze jednego zadania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. dodatkowe** Przekształć kod z regresji dwuklasowej, żeby działał z regresją softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
