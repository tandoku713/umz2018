{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresja logistyczna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W zeszły tygodniu poznaliśmy pierwszy klasyfikator $k$ najbliższych sąsiadów. Dziś będziemy kontynuować temat klasyfikacji. Zaczniemy od szczególnego przypadku jakim jest klasyfikacja binarna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikacja binarna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasyfikacja binarna jest szczególnych rodzajem, ponieważ mamy tylko dwie klasy. Bardzo często zdarza się, że chcemy przewidzieć, czy zaszło dane zjawisko, np. czy będzie dziś padać deszcz, czy przydzielić kredyt hipoteczny, przeżycie katastrofy Titanica itd. Będziemy przyjmonować następującą konwencję:\n",
    " * klasa 1 - zaszło dane zjawisko (np. przeżył)\n",
    " * klasa 0 - nie zaszło dane zjawisko (np. umarł)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasyfikator może popełnić dwa rodzaje błędów:\n",
    " * przewidzieć 1, gdy w rzeczywistości było 0 (błąd I rodzaju, *false positive*, FP)\n",
    " * przewidzieć 0, gdy w rzeczywistości było 1 (błąd II rodzaju, *false negative*,FN).\n",
    " \n",
    "Niestety te dwa błędy wykluczają się: jeżeli nasz model będzie zawsze zwracał klasę 0, to nigdy nie popełni błędu pierwszego rodzaju. Podobnie w sytuacji, gdy zawsze będzie zwracał wartość 1: nigdy nie popełni błędu drugiego rodzaju."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precyzja i pokrycie (ang. precision and recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Istnieją dwie miary, które mierzą precyzję i pokrycie:\n",
    " * **precyzja**: mierzy pewność klasyfikatora, czyli. błąd I rodzaju: $$ PRECISION = \\frac{TP}{TP+FP} $$\n",
    " * **pokrycie**: mierzy zasięg klasyfikatora, czyli błąd II rodzaju: $$ RECALL = \\frac{TP}{TP + FN} $$\n",
    " \n",
    "Gdzie TP (*true positive*) to liczba elementów dobrze zaklasyfikowanych w klasie 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**przykład 1** Weźmy pod uwagę zestaw danych z Titanica (``dev-0``). Nasz model działa tylko na podstawie płci, tzn. przewiduje 1 (przeżycie) wyłącznie gdy zadana osoba jest kobietą. Przedstawmy wyniki w postaci tabeli (ang. confusion matrix):\n",
    "\n",
    "|   | 1  | 0  |\n",
    "|---|----|----|\n",
    "| 1 | 36 | 10 |\n",
    "| 0 | 13 | 75 |\n",
    "\n",
    "Kolumny: stan faktyczny, wiersze: predykcja modelu.\n",
    "\n",
    "Zatem: $$PRECISION = \\frac{36}{36 + 10} = \\frac{36}{46}$$ i $$ RECALL = \\frac{36}{36 + 13} = \\frac{36}{49} $$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 1** Napisz fukcję, która oblicza precyzję i recall na podstawie tabeli. Dane będą podawane wierszami, tj. dla powyższego przykładu: ``[[36, 10], [13, 75]]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "data = [[36, 10], [13, 75]]\n",
    "\n",
    "def precision_and_recall(dane):\n",
    "    pass\n",
    "\n",
    "print(precision_and_recall(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 2** Zamiana klas. Oblicz precyzję i recall dla zadania, w którym chcemy przewidzieć, czy ktoś **nie** przeżył katastrofy Titanica. Wykorzystaj dane z przykładu 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 3** Wykorzystaj model z ostatniego zadania domowego i oblicz precyzję i pokrycie na zbiorze ``dev-0``. Wykorzystaj fukcję ``classification_report`` z modułu ``sklearn.metrics``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja logistyczna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystanie regresji logistyczne z pakietu ``sklearn`` nie różni się od wykorzystania innych modeli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na podstawie ogłoszeń mieszkań będziemy chcieli przewidzieć, czy dane mieszkanie znajduje się w centrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"gratkapl-centrenrm.csv\")\n",
    "X = data[['Expected','Rooms','SqrMeters', 'Floor']]\n",
    "Y = data['Centre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(train_X, test_X, train_Y, test_Y) = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizacja danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykonajmy normalizacje danych wejściowych (odjęcie średniej i podzielenie przez otchylenie std). Wykorzystamy do tego narzędzie ``StandardScaler``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(train_X)\n",
    "\n",
    "train_X = scaler.transform(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 4** Korzystając z dokumentacji wyświetl średnią dla każdej z kolumn wejściowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wytrenujmy model regresji logistycznej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 5** Wyświetl parametry modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(scaler.transform(test_X)) # dane testowe też muszą zostać znormalizawane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.97      0.83       288\n",
      "          1       0.58      0.09      0.16       116\n",
      "\n",
      "avg / total       0.68      0.72      0.64       404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mierzenie zależności pomiędzy precyzją i pokryciem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W najlepszym przypadku chcielibyśmy zminimalizować błędu obu rodzajów. Niestety, nie zawsze jest to możliwe. Bardzo często można zwiększyć pokrycie kosztem precyzji i na odwrót: zwiększyć precyzję kosztem pokrycia.\n",
    "\n",
    "Dlatego wprowadza się dwie miary:\n",
    " * F-score: $$ FSCORE = \\frac{2}{\\frac{1}{PRECISON} + \\frac{1}{RECALL}} $$\n",
    " * Krzywa [ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. (domowe)** Uruchom regresję logistyczną na zbiorze Titanic:\n",
    " * Wykorzystaj arkusz z poprzedniego zadania domowego.\n",
    " * Wykonaj normalizacje danych na wybranych kolumnach? Jak zmieniły się wyniki?\n",
    " * korzystając z implementacji z ``sklearn`` wyświetl krzywą ROC na ``dev-0``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
